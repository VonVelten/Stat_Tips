Les méthodes de machine learning peuvent être relativement gourmandes en termes de temps de calcul. Pour éviter une compilation du document demandant 3 jours, l'ensemble du code sera mis en commentaire, pou rêtre accessible mais éviter de ne pouvoir compiler ce document.

## A propos des données utilisées dans ce document

## Validation d'un modèle de Machine Learning

Part d'un ensemble de variables X et une variable Y réponse. On découpe X en deux sous-jeu de données, X$_1$ et X$_2$. On appelle X$_1$ le jeu de données d'entraînement ou d'apprentissage. Il permet d'ajuster un modèle pour prédire Y. X$_2$ est le jeu de données test ou de validation. On peut alors prédire ses sorties Y$_2$' à partir du modèle ajusté obtenu précédemment. On parle alors de validation croisée (car on croise deux jeux de données indépendant pour l'ajustement et la validation).

Pour des variables qualitatives bimodales, on peut alors définir une matrice de confusion :

```{=tex}
\begin{table}[!h]

  \begin{tabular}{ll|cc}
  & & Comportements& prédits \\
  &&Modalité A & Modalité B\\
  \hline
  Comportements&Modalité A & VP&FN\\
  observés&Modalité B&FP&VN\\
  \hline
  \end{tabular}
  \caption{Matrice de confusion en machine learning}

\end{table}
```


avec

-   VP : Vrai Positif
-   FN : Faux Négatif
-   FP: Faux Positif
-   VN : Vrai Négatif

On peut alors définir plusieurs indicateurs sur la qualité de la prédiction:

-   Le pourcentage de bon classement : $\frac{VP+VN(?)}{VP+VN+FP+FN}*100$
-   La sensibilité : $\frac{VP}{VP+FN}$, la capacité à bien identifier les vrais positifs. Un test très sensible signifiera que toute modalité A sera bien détectée.
-   La spécificité :$\frac{VN}{FP+VN}$, la capacité à bien discriminer les vrais négatifs. Un test très spécifique ne donnera jamais de faux positif.

Pour éviter des effets aléatoires sur les résultats de ces indicateurs liés à la sélection des individus, on peut réaliser de la validation croisée répétée (K-fold cross validation). On prend alors 90% des données pour l'entraînement(on parle de données dans le bag), et on valide sur les 10% de données restants(données dites out-of-bag). On réalise cela 10 fois, de façon à que chaque donnée aient fait parti une fois du jeu de données de validation. On obtient pour chacun des dix ajustements une matrice de confusion. Pour avoir la matrice de confusion globale, on somme chacune des dix matrices obtenues avant. On calcule alors les métriques de performances sur cette matrice de confusion globale. On peut également réaliser du Leave-one-out validation. Cela consiste à ne laisser d'un seul individu en dehors du bag.

Lors de ces validations, il faut fait attention à la stratification des données, c'est-à-dire que dans chaque sous-jeu de données, les modalités à prédire doivent avoir des occurrences les plus proches possibles du jeu de données initiales pour éviter des soucis liés à ces différences d'occurrence.

## Support Vector Machine (SVM)

### Principe de l'algorithme

C'est une méthode de classification de machine learning développée dans les années 1990 sur la base de la théorie de Vapnik-Tchervonenkis. elle prédit des variables qualitatives à partir de variables qualitatives et quantitatives. Cette méthode a été adoptée dans une diversité de domaines : aptitude à travailler avec des données de grandes dimensions, faible nombre d'hyperparamètres à ajuster et très bons résultats. Le principe du SVM est de trouver une surface de décision, appelée *hyperplan*, qui discrimine au mieux les échantillons selon leur classe.

Si on suppose la distribution des échantillons selon (X$_1$,X$_2$), alors l'algorithme SVM identifie l'hyperplan qui discrimine au mieux les deux types d'échantillon. Ceci se fait à l'aide d'une équation de l'hyperplan $b+w_1X_1+w_2+X_2=0$, avec X$_1$ et X$_2$ les deux variables du jeu de données, $w_1$ et $w_2$ les pods associés à chacune des variables, et $b$ une constante. On définit alors deux domaines, positif ou négatif, par rapport à la valeur données par l'équation $b+w_1X_1+w_2+X_2$, qui définissent alors à laquelle des deux modalités chaque échantillon sera attribué.

Si on définit $y_i$ la réponse à l'échantillon $x_i$ avec des valeurs possibles -1 et +1, alors l'échantillon est bien classé uniquement si $y_i(b+w_1X_1+w_2+X_2) > 0$.

### Fonctionnement de l'algorithme

Pour déterminer l'hyperplan optimal parmi l'infinité de possibilité, l'algorithme SVM utilise la *méthode de la marge*. Il recherche pour cela la plus courte distance qui séparent les échantillons les plus proches de l'hyperplan, aussi appelés *vecteurs supports* (support vector).


![Principe de l'algorithme SVM](ML/SVM_plan.png){ height=512px }




#### Etape 1 : Expression de la Marge

Si on considère $M_S$ un jeu de donné, alors $M_S$ est défini par ses variables $X_{S,k}$ (k étant un entier natuer), et associé à la classe $y_S$ qui vaut -1 ou +1. On suppose que $M_S$ est un vecteur support potentiel. Soit H l'hyperplan défini par l'équation $b+w_1X_1+w_2+X_2=0$? Connaissant l'équation du plan, on peut définir un vecteur normal au plan noté $\vec{w}$ de coordonnées (w$_1$;w$_2$). On définit alors la marge comme la plus courte distance qui sépare les échantillons les plus proches de l'hyperplan et l'hyperplan H. On réalise alors une projection orthogonale de $M_S$ sur ce plan. Le problème revient donc à calculer la distance associé à la projection orthogonale d'un point de coordonnées connues sur un plan défini par son équation cartésienne. On peut donc avoir :

```{=tex}
\begin{center}
  $marge=d(M_S,H)=\frac{|b+w_1X_1+w_2+X_2|}{\sqrt{w_1^2+w_2^2}}$
\end{center}
```

#### Etape 2 : Maximisation de la marge

L'hyperplan optimal est alors celui qui permet de maximiser la marge. Il existe une infinité de solutions pour $b$, $w_1$ et $w_2$ tels que $|b+w_1X_1+w_2+X_2| = 1$, avec $M_S$ un vecteur support.

On ajoute alors la contrainte de deux frontières, positives et négatives, tel que :

```{=tex}
\begin{center}

Frontière + : $b+w_1X_{S1}^{+}+w_2+X_{S2}^{+}=1$

Frontière - :  $b+w_1X_{S1}^{-}+w_2+X_{S2}^{-}=-1$

\end{center}
```

avec :

-   $M_S^{+}(X_{S1}^{+},X_{S2}^{+})$ un vecteur support appartenant à la frontière positive
-   $M_S^{-}(X_{S1}^{-},X_{S2}^{-})$ un vecteur support appartenant à la frontière négative

En considérant la condition de normalisation, le problème revient à trouver les coefficients $b$, $w_1$ et $w_2$ tels que :

1.  La condition $y_i(b+w_1X_1+w_2+X_2) \geq 1$ soit satisfaite pour tout échantillon $P_i$ du jeu de données

    -   Si $y_i=-1$, alors l'échantillon est bien classé s'il est à gauche de la frontière négative définie par $b+w_1X_{S1}^{-}+w_2+X_{S2}^{-} \leq -1$, soit $y_i(b+w_1X_{S1}^{-}+w_2+X_{S2}^{-}) \geq 1)$

    -   Si $y_i=1$, alors l'échantillon est bien classé s'il est à droite de la frontière positive définie par $b+w_1X_{S1}^{+}+w_2+X_{S2}^{+} \geq 1$, soit $y_i(b+w_1X_{S1}^{-}+w_2+X_{S2}^{-}) \geq 1)$

2.  L'expression $\sqrt{w_1^2+w_2^2}$ soit minimale : En considérant la condition de normalisation $|b+w_1X_1+w_2+X_2| = 1$, on a $marge = \frac{1}{\sqrt{w_1^2+w_2^2}}$. Maximiser la marge revient donc à minimiser $\sqrt{w_1^2+w_2^2}$. On se retrouve donc à devoir minimiser $\sqrt{w_1^2+w_2^2}$ sous la contrainte $y_S (b+w_1X_{S1}+w_2X_{S2}) \geq 1$. ce problème est résolu par la méthode des multiplicateurs de Lagrange.

Remarque : L'explication a été réalisé avec un jeu de données à 2 variables. Le problème est généralisable avec m \>\> 2 variables. On recherche alors l'hyperplan suivant : $b+\sum_{i=1}^mw_iX_i=0$. Trouver l'hyperplan optimal revient alors à minimiser $\sqrt{\sum_i^mw_i^2}$ sous la contrainte $y_S(b+\sum_i^mw_iX_{Si})\geq1$.

Dans l'exemple déroulé, il y avait l'hypothèse qu'aucun échantillon ne doit être compris dans la marge. En pratique, cette contrainte peut mener à un sur-ajustement du modèle, et on risque d'avoir une une surface de décision trop spécifique au jeu de données utilisé pour l'apprentissage. On définit alors la **marge souple**, ou **marge faible**, c'est-à-dire une tolérance d'un certains nombres d'échantillons dans la marge. Cette tolérance est régulée par l'hyperparamètre C, dit paramètre de régularisation du SVM.

De plus, dans le cas précédent, l'hypothèse était que les échantillons peuvent êtres discriminés par un séparateur strictement linéaire, mais ce n'est que rarement le cas. Pour cela, on permet de reconsidérer le problème en introduisant de nouvelles dimensions à l'aide d'une fonction de noyau. On définit alors $\phi(X)$, l'espace de redescription. L'objectif est alors de trouver un séparateur linéaire dans ce nouvel espace $\phi$. Cela revient à appliquer aux variables d'entrée X une transformation non-linéaire notée $\phi$ et de trouver l'hyperplan optimal dans cet espace de redescription. En pratique, deux fonctions de noyau sont généralement utilisés :

-   Le noyau polynomial : $\phi(X_1,X_2)=(a+\sum_i^NXi{i1}X_{i2})^b$ avec N le nombre d'échantillons, $(X_1,X_2)$ les deux variables, $b$ le degré du polynome et $a$ une constante
-   La fonction de base radiale : $\phi(X_1,X_2)=e^{-\gamma ||X_1-X_2||^2}$, avec $||X_1-X_2||$ la distance euclidienne entre les variables, et $\gamma$ un paramètre de contrôle du sur-ajustement.

*Références* : Yadav, A., 2018. Support Vector Machines (SVM) [WWW Document]. Data Sci. URL <https://towardsdatascience.com/support-vector-machines-svm-c9ef22815589>

### Mise en place sous R

Pour la mise en place, on utilisera deux packages, **carnet** et **kernlab**. Il est aussi important d'avoir deux jeux de données, un d'entraînement (ou d'apprentissage) et n de validation

```{r}
rm(list=ls())
library(caret)
library(kernlab)

# traindata : jeu de données d'entraînements
# test_select : jeu de données de validation

load(file="ML/PartieApplications/SVM/testdata.Rdata")
load(file="ML/PartieApplications/SVM/traindata.Rdata")


#  RECHERCHE DES PARAMETRES OPTIMAUX
##  CREATION DE LA GRILLE DE PARAMETRISATION ET METHODE POUR TROUVER LES PARAMETRES OPTIMAUX
# Vu qu'il y a une part d'aléatoire dans l'initialisation, il est important de fixer la "seed",
# C'est à dire l'aléatoire, pour pouvoir reproduire les résultats.
# svm.seed=111
# set.seed(svm.seed)
# On précise les règles d'apprentissages liés au pacakge
# fitControl <- trainControl(method="repeatedcv", # on fait de la cross-validation répétée
#                            number=10, # combien d'iteration
#                            repeats=3, #nombre de jeu de donnée pour la cross-validation repétée
#                            search="grid", # on
#                            allowParallel=TRUE) # possibilité de travailler sur plusieurs coeurs
# Quelles valeurs de sigma et C on va tester
# mygrid <- expand.grid(sigma=seq(0.01,0.1,by=0.01),
#                       C=c(1,2,5,10,50,100,120,140,160,180,200,250,300,350,400,450,500,1000)) # + valeurs de C élevées --> + marge est stricte
# metric <- "Accuracy"

##  AJUSTEMENT DU MODELE SVM
# svm.fit <- train(y ~ ., data=traindata, # On cherche à prédire y en fonction de toutes les variables
#                  method="svmRadial", #on utile sur SVM avec coeur Radial
#                  trControl=fitControl, # on utilise les conditions d'apprentissages
#                  metric=metric, # Quelle métrique est utilisée
#                  preProcess=NULL,
#                  tuneGrid=mygrid) # Quelle valeurs on teste.


# Chargement des résultats, pour éviter de perdre du temps
load(file = "ML/PartieApplications/SVM/2019-04-21_model_SVM_TFEN10RECV90NORM.Rdata")

##  PARAMETRES DU MODELE AJUSTE
# On cherche le meilleur couple d'hyperparamètres simga/C
svm.fit$bestTune
plot(svm.fit)

#  EVALUATION DES PERFORMANCES DE ML

##  PERFORMANCE DU MODELE SUR JEU DE DONNEES D'ENTRAINEMENT
# On prédit les nouvelles valeurs sur le jeu de données d'entraînement
 # svm.predictions=predict(svm.fit, newdata=traindata)
 # save(file = "ML/PartieApplications/SVM/predictions_train.Rdata",svm.predictions)
# On charge les résultats de la prédictions avec les données d'entrainement
load(file = "ML/PartieApplications/SVM/predictions_train.Rdata")
perf_svm_fit_traindata <- confusionMatrix(data=svm.predictions,reference=traindata$y,positive=NULL)

##  PERFORMANCE DES DIFFERENTS MODELES TESTES PAR VALIDATION CROISEE
perf_svm_fit_cv <- subset(svm.fit$results,
                          C == svm.fit$bestTune$C & sigma == svm.fit$bestTune$sigma,
                          c("Accuracy", "Kappa"))
perf_svm_fit_cv
##  EVALUATION DE LA QUALITE DU MODELE AVEC LE JEU DE DONNEES TEST
# svm.predictions=predict(svm.fit, newdata=testdata)
# save(file = "ML/PartieApplications/SVM/predictions_test.Rdata",svm.predictions)
load(file = "ML/PartieApplications/SVM/predictions_test.Rdata")
perf_svm_fit_testdata <- confusionMatrix(data=svm.predictions,reference=testdata$y,positive=NULL)

mat_conf_svm <- t(perf_svm_fit_testdata$table) # Donne la matrice de confusion
# Quelles métriques pour la prédictino du jeu de données de validation
metric_overall_svm <- perf_svm_fit_testdata$overall
metric_byClass_svm <- perf_svm_fit_testdata$byClass

# ANALYSE DE L'IMPORTANCE DES VARIABLES

svm.varImp <- varImp(svm.fit, scale=TRUE)
## Classement par ordre d'importance global
imp_globale <- sort(apply(svm.varImp$importance, 1,function(x){sqrt(sum(x^2))}), decreasing = TRUE)
## Variables les plus discriminantes pour les comportements les plus durs à discriminer
imp_standing_none <- data.frame(name = rownames(svm.varImp$importance), imp = svm.varImp$importance$Standing...None)
imp_standing_none <- imp_standing_none[order(imp_standing_none$imp, decreasing = TRUE),]
top_20_standing_none  <- imp_standing_none[1:20,"name"]

imp_walking <- data.frame(name = rownames(svm.varImp$importance), imp = svm.varImp$importance$Walking)
imp_walking <- imp_walking[order(imp_walking$imp, decreasing = TRUE),]
top_20_walking  <- imp_walking[1:20,"name"]

# #  GENERER LES RESULTATS
# save(mat_conf_svm, file = "mat_conf_svm.RData")
# save(metric_overall_svm, file = "metric_overall_svm.RData")
# save(metric_byClass_svm, file = "metric_byClass_svm.RData")
# write.csv2(svm.varImp$importance, file = "varImp.svm.csv", dec = ".", sep = ";")

```

## Random Forest

Il s'agit d'un algorithme de machine learning relativement simple et intuitif développé par Breiman et al. en 1984. Ses applications sont de la classification supervisée (variable réponse qualitative) ou de la régression (variable réponse quantitative). Elle appartient à la technique de bagging. Le principe est la création d'un ensemble d'arbres de décisions (ou de classification) de façon indépendante à partir d'un sous-ensemble d'échantillons choisi de manière aléatoire. Ceci donne alors une multitute d'arbres différents. Une fois la forêt (multitude d'arbre) obtenue, la classe associée à un nouvel échantillon est celle prédite par un vote majoritaire.

### Définition d'un arbre de classification

![Structure d'un arbre de classification](ML/Tree.png)

Pour chaque noeud est associée une condition pour séparer le noeud parent et les noeuds enfants. A chaque noeud, l'objectif est de choisir la condition qui maximise la diminution d'impureté (i.e. l'hétérogénéité) des noeuds enfants à partir du noeud parent. Pour cela, on utile l'index de Gini(G), défini par :

```{=tex}
\begin{center}
$G=\sum_k^Np_k(1-p_k)$
\end{center}
```

avec N le nombre de classe (le nombre de modalité de la variable qualitative), et $o_k$ la proportion d'échantillons correspondant au comportement $k$ dans le noeud. S'il n'y a aucune impureté, alors G vaudra 0 (100 x 0), et sa valeur maximale est de 0.25 (50% x 50%). L'objectif est donc de diminuer l'impureté des noeuds en limitant le nombre de noeuds et branches nécessaires pour arriver aux feuilles terminales, on parle de **profondeur de l'arbre**. Cette profondeur conditionne directement le niveau de complexité de l'arbre. En augmentant cette complexité, il y a le risque d'avoir un sur-ajustement du modèle, avec un arbre qui serait trop spécifique du jeu de données d'entraînement. Pour cela, il y a un contrôle du sur-ajustement en imposant un nombre minimal d'échantillons dans chaque noeud ou en fixant un nombre maximal de branches à ne pas dépasser.

Il est aussi possible de réaliser un **elagage de l'arbre**. Il s'agit d'une technique pour améliorer les performances de l'arbre une fois celui-ci obtenu. Pour cela, on va supprimer des branches qui utilisent des variables dont l'importance relative est faible. Cela améliore ainsi son pouvoir prédictif en réduisant sa complexité, et en limitant ainsi les risques de sur-ajustement. La méthode classique d'élagage consiste en la construction d'une suite d'arbres à partir de l'arbre obtenu en l'élaguant successivement. L'arbre conservé est celui qui garantit le meilleur compromis entre la taille de l'arbre et son coût de mauvais classement. On utilise pour cela le critère de complexité $\alpha$ de Breiman

$\alpha = \frac{\epsilon(elagué(T,F),E)-\epsilon(T,E)}{nb\_feuilles(T)-nb\_feuilles(élagué(T,f))}$

avec $elagué(T,F)$ l'arbre T élagué de la feuille $f$, $\epsilon(T,E)$ l'erreur obtenu sur un échantillon E du jeu de données avec l'arbre T.

Remarque : Une procédure de cross-validation est souvent utilisée à cette étape pour générer l'échantillon E. D'autres approches peuvent être mises en oeuvre pour trouver le sous-arbre optimal mais le principe général reste le même.

### Principe de l'algorithme de forêt aléatoire

On considère $t$ le nombre de l'itération.

#### Etape 1 : Construction des arbres

Soit t=1, On crée alors un nouveau jeu de donnée par la technique du bootstrap (Tirage aléatoire de n échantillons avec remise). Dans cet échantillon, certains échantillons ne sont jamais tirés, d'autres tirés plusieurs fois. Les échantillons qui n'ont jamais tirées sont ceux dits "**out-of-bag**".

On construit alors un arbre sur le jeu de données bootstrappé, avec $m$ variables aléatoires à chaque noeud. Pour chaque noeud :

1.  On tire de façon aléatoire m variables aléatoires (m\<p). Par défaut, $m=\sqrt{p}$.

2.  La condition retenue sur l'une des variables tirées est celle qui discrimine au mieux les échantillons, donc celle qui minimise l'index de Gini.

Au noeud suivant, $m$ variables sont de nouveau tirées aléatoirement (donc potentiellement d'autres variables). On reprend les mêmes règles de décision. On continue la construction de l'arbre jusqu'à atteindre les paramètres limitant le sur-ajustement soient atteints. Lorsque l'arbre de l'itération t = 1 est terminé, l'algorithme réitère les étapes pour t=2, et ainsi de suite jusqu'à ce que t = T.

#### Etape 2 : Evaluation de la classification de chacun des arbres

On mesure les performances de classification de chacun des arbres, puis de la forêt, calculées par l'algorithme. Pour chaque arbre, on utilise les OOB pour tester les performances de prédiction de chaque arbre. Cela permet d'avoir une évaluation robuste de chacun des classifieurs. On définit alors l'erreur moyenne de la forêt aléatoire comme la moyenne des erreurs obtenues par chacun des arbres. Pour la prédiction d'un nouvel échantillon, la prédiction est celle obtenue par la majorité des arbres.

*Références* :

-   Breiman, L., Friedman, J., Olshen, R., Stone, C., 1984. Classification and Regression Tree, Wadsworth International. California.

-   Breiman, L., 2001. Random Forests. Mach. Learn. 45, 5--32.

-   Chauhan, N., 2019. Decision Tree Algorithm --- Explained [WWW Document]. Data Sci. URL <https://towardsdatascience.com/decision-tree-algorithm> explained-83beb6e78ef4

### Mise en place de Random Forest sous R.

```{r}
library(caret)
library(kernlab)

# traindata : jeu de données d'entraînements
# test_select : jeu de données de validation

load(file="ML/PartieApplications/SVM/testdata.Rdata")
load(file="ML/PartieApplications/SVM/traindata.Rdata")


#  RECHERCHE DES PARAMETRES OPTIMAUX

##  CREATION D'UNE PARAMETRISATION EXTENSION DE CARET (CODE SP)
customRF <- list(type="Classification", # On réalise une classification
                 library="randomForest", # On va réaliser du random forest
                 loop=NULL)
customRF$parameters <- data.frame(parameter=c("mtry", "ntree"), class=rep("numeric", 2), label=c("mtry", "ntree"))
customRF$grid <- function(x, y, len=NULL, search="grid") {}
customRF$fit <- function(x, y, wts, param, lev, last, weights, classProbs, ...) {
  randomForest(x, y, mtry = param$mtry, ntree=param$ntree, ...)
}
customRF$predict <- function(modelFit, newdata, preProc = NULL, submodels = NULL)
  predict(modelFit, newdata)
customRF$prob <- function(modelFit, newdata, preProc = NULL, submodels = NULL)
  predict(modelFit, newdata, type = "prob")
customRF$sort <- function(x) x[order(x[,1]),]
customRF$levels <- function(x) x$classes

##  CREATION DE LA GRILLE DE PARAMETRISATION ET METHODE POUR TROUVER LES PARAMETRES OPTIMAUX
set.seed(111) # on fixe la seed
metric <- "Accuracy"
# Comme pour SVM, on précise les
control <- trainControl(method="repeatedcv", number=10, repeats=3, search = "grid")
tunegrid <- expand.grid(.mtry=c(7,10,15,20,25), # nombre de variable utilisé par noeud
                        .ntree=c(500,1000,1500,2000)) # nombre d'arbre dans la forêt

## AJUSTEMENT DU MODELE DE RF

# custom_rf <- train(y~., data=traindata, method=customRF, metric=metric, tuneGrid=tunegrid, trControl=control)


load(file = "ML/PartieApplications/RF/2019-04-29_model_RF_TFEN10RECV90NORM.RData")

# PARAMETRES DU MODELE AJUSTE
custom_rf$bestTune
plot(custom_rf)

# EVALUATION DES PERFORMANCES DE ML
summary(custom_rf)

##  PERFORMANCE DU MODELE SUR JEU DE DONNEES D'ENTRAINEMENT
# rf.predictions=predict(custom_rf, newdata=traindata)
# save(file="ML/PartieApplications/RF/Pred_train.Rdata",rf.predictions)
load(file="ML/PartieApplications/RF/Pred_train.Rdata")
perf_custom_rf_traindata <- confusionMatrix(data=rf.predictions,reference=traindata$y,positive=NULL)

## PERFORMANCE DES DIFFERENTS MODELES TESTES PAR VALIDATION CROISEE

perf_custom_rf_cv <- subset(custom_rf$results, mtry == custom_rf$bestTune$mtry & ntree == custom_rf$bestTune$ntree, c("Accuracy", "Kappa"))

##  EVALUATION DE LA QUALITE DU MODELE AVEC LE JEU DE DONNEES TEST
# rf.predictions=predict(custom_rf, newdata=testdata)
# save(file="ML/PartieApplications/RF/Pred_test.Rdata",rf.predictions)
load(file="ML/PartieApplications/RF/Pred_test.Rdata")
perf_custom_rf_testdata <- confusionMatrix(data=rf.predictions,reference=testdata$y,positive=NULL)

mat_conf_rf <- t(perf_custom_rf_testdata$table)
metric_overall_rf <- perf_custom_rf_testdata$overall
metric_byClass_rf <- perf_custom_rf_testdata$byClass
metric_byClass_rf

#  ANALYSE DE L'IMPORTANCE DES VARIABLES

rf.varImp <- varImp(custom_rf, scale=TRUE)
## Classement par ordre d'importance global
imp_globale <- sort(apply(rf.varImp$importance, 1,function(x){sqrt(sum(x^2))}), decreasing = TRUE)
## Variables les plus discriminantes pour les comportements les plus durs à discriminer
imp_standing_none <- data.frame(name = rownames(rf.varImp$importance), imp = rf.varImp$importance$Standing...None)
imp_standing_none <- imp_standing_none[order(imp_standing_none$imp, decreasing = TRUE),]
top_20_standing_none  <- imp_standing_none[1:20,"name"]

imp_walking <- data.frame(name = rownames(rf.varImp$importance), imp = rf.varImp$importance$Walking)
imp_walking <- imp_walking[order(imp_walking$imp, decreasing = TRUE),]
top_20_walking  <- imp_walking[1:20,"name"]

#  GENERER LES RESULTATS
# save(mat_conf_rf, file = "ML/PartieApplications/RF/mat_conf_rf.RData")
# save(metric_overall_rf, file = "ML/PartieApplications/RF/metric_overall_rf.RData")
# save(metric_byClass_rf, file = "ML/PartieApplications/RF/metric_byClass_rf.RData")
# write.table(rf.varImp$importance, file = "ML/PartieApplications/RF/varImp.rf.csv", dec = ".", sep = ";")
```

## AdaBoost

Il s'agit d'une méthode ensembliste de machine learning utilisée pour des problèmes de classification supervisée. Il s'agit d'un méta-alogirthme de boosting qui utilise généralement un arbre de décision comme classifieur faible. Le principe est de booster successivement les performances de classifieurs faibles en donnant plus de poids aux échantillons mals classés par le classifieur courant. Il peut prendre en compte toutes les sorties des classifieurs faibles avec une pondération qui dépend des perofrmances respectives dans la décision finale prise par le classifieur fort.

### Fonctionnement de l'algorithme

#### Etape 1 : Identification du premier classifieur faible

Soit T le nombre maxiumum d'itérations, et t=1 la première itération. Adaboost commence par identifier un premier classifieur faible noté $h_{t=1}$, un arbre de décision constitué uniquement de deux feuilles ("**stump**") qui divise le jeu de données en groupes les plus homogènes possibles. Pour cette première étape, on considère que chaque échantillon a rigourement la même importance (i.e., le même poids), dans le calcul de l'erreur de classification. D'un point de vue algorithmique, cela revient à trouver $h_{t=1}$ qui minimise l'erreur de classification notée $\epsilon_{t=1}$.

On peut alors définir :

```{=tex}
\begin{center}
  $h_{t=1}=argming(\epsilon_{t=1})$
  
  $\epsilon_{t=1}=\sum^n_{i=1}w_{t=1}(i)[y_i\ne h_{t=1}(X_{i1},X_{i2})]$
\end{center}
```

avec

-   $w_{t=1}(i)=\frac{1}{n}$, le poids affecté à tout échantillon i du jeu de données à t=1

-   $y_i\ne h_{t=1}(X_{i1},X_{i2})$ : qui vaut 1 si le comportement obtenu avec $h_{t=1}$ pour l'échantillon i à partir des variables $(X_{i1},X_{i2})$ doffère du comportement observé $y_1$, 0 sinon.

Remarque : Par définition, un classifieur faible doit résulter sur une erreur de classification strictement inférieure à celle qui aurait été obtenue par hasard ($\epsilon_t$ \< 0.5 dans ce cas particulier). L'algorithme s'arrêtera si aucun classifieur satisfaisant cette condition n'a pu être trouvé.

#### Etape 2 : Calcul et mise à jour des poids.

On Calcule alors le poids du classifier $h_{t=1}$, notée:

```{=tex}
\begin{center}
$\alpha_{t=1}=\frac{1}{2}log(\frac{1-\epsilon_{t=1}}{\epsilon_{t=1}})$. 
\end{center}
```

$\alpha_{t=1}$ sera d'autant plus élevé que le classifieur est performant, c'est-à-dire qu'il minimise l'erreur $\epsilon_t$. On met alors à jour le poids de chaque échantillon i du jeu de données, noté \$w\_{t=2}(i) pour la deuxième itération :

```{=tex}
\begin{center}
$w_{t=2}(i)=\frac{w_{t=1}(i)e^{-\alpha_{t=1}y_ih_{t=1}(X_{i1},X_{i2})}}{Z_{t=1}}$
\end{center}
```

avec $Z_{t=1}$ le facteur de normalisation qui garantit que la somme des poids sur i vaut 1. Du coup $Z_{t=1}=2\sqrt{\epsilon_{t=1}(1-\epsilon_{t=1})}$. Pour chacun des échantillons i, il y a deux cas possibles :

-   L'échantillon i est bien classé $y_ih_{t=1}(X_{i1},X_{i2})=1$, alors $f(\alpha_{t=1})=e^{-\alpha_{t=1}y_ih_{t=1}(X_{i1},X_{i2})}$. Si l'échantillon est bien classé, le nouveau poids pour cet échantillon sera d'autant plus faible que le classifieur $h_{t=1}$ est performant (i.e. que $\alpha_{t=1}$ est élevé)

-   L'échantillon i est mal classé $y_ih_{t=1}(X_{i1},X_{i2})=-1$, alors $f(\alpha_{t=1})=e^{-\alpha_{t=1}y_ih_{t=1}(X_{i1},X_{i2})}$. Si l'échantillon est mal classé, le nouveau poids pour cet échantillon sera d'autant plus fort que le classifieur $h_{t=1}$ est performant (i.e. que $\alpha_{t=1}$ est élevé)

Les poids $w_{t=2}$ les plus élevés seront affectés aux échantillons qui sont mal classés par le classifieur $h_{t=1}$.

#### Etape 3 : Identification du second classifieur faible

A l'itération t=2, un second classifieur faible noté $h_{t=2}$ qui minimise l'erreur de classification $\epsilon_{t=2}$. On définit alors l'erreur de classification :

```{=tex}
\begin{center}
  $\epsilon_{t=2}=\sum_{i=1}^nw_{t=2}(i)[y_i\ne h_{t=2}(X_{i1},X_{i2})]$
\end{center}
```

On peut noter que $w_{t=2}(i)>\frac{1}{n}$ si l'échentillon était mal classé à la première itération. On reconduit ensuite les étapes 2 et 3 de façon itératirve jusqu'à ce que t=T, le nombre maximal d'itération, ou que l'amélioriation ne soit lié qu'au hasard.

#### Etape 4 : Définition du classifieur fort

Un classifieur fort est obtenu à l'issue des T itérations $H_{X_1,X_2}$ :

```{=tex}
\begin{center}
  $H_{X_1,X_2}=signe(\sum_{t=1}^T\alpha_th_t(X_1,X_2))$
\end{center}
```

On utilise la comme de chacun des sorties des classifieurs faibles (+1 ou -1), en affectant un poids plus ou moins fort selon la performance du classifieur. Pour prédire le comportement d'un nouvel échantillon i, on utilise donc un vote pondérée sur les décisions de chacun des classieurs faibles.

*Références* :

-   Fabien, M., 2019. Boosting and AdaBoost clearly explained [WWW Document]. Data Sci. <https://towardsdatascience.com/boosting-and-adaboost-clearly-explained-856e21152d3e>

### Mise en place sous R

```{r}

library(caret)
library(kernlab)

# traindata : jeu de données d'entraînements
# test_select : jeu de données de validation

load(file="ML/PartieApplications/SVM/testdata.Rdata")
load(file="ML/PartieApplications/SVM/traindata.Rdata")


#  RECHERCHE DES PARAMETRES OPTIMAUX

##  CREATION DE LA GRILLE DE PARAMETRISATION ET METHODE POUR TROUVER LES PARAMETRES OPTIMAUX
set.seed(111)
metric <- "Accuracy"
control <- trainControl(method="repeatedcv", number=10, repeats=3, search="grid", allowParallel=TRUE)
tunegrid <- expand.grid(mfinal=c(100,150), maxdepth=c(10:30))

##  AJUSTEMENT DU MODELE ADABOOST

# adaboost.fit <- train(y~., data=traindata, method="AdaBag", metric=metric, tuneGrid=tunegrid, trControl=control)
load(file = "ML/PartieApplications/Ada/2019-04-22_model_ADABOOST_TFEN10RECV90NORM.RData")

##  PARAMETRES DU MODELE AJUSTE
adaboost.fit$bestTune
plot(adaboost.fit)

# EVALUATION DES PERFORMANCES DE ML
summary(adaboost.fit)

## PERFORMANCE DU MODELE SUR JEU DE DONNEES D'ENTRAINEMENT
# ada.predictions=predict(adaboost.fit, newdata=traindata)
# save(file="ML/PartieApplications/Ada/Pred_train.Rdata",ada.predictions)
load("ML/PartieApplications/Ada/Pred_train.Rdata")
perf_adaboost_fit_traindata <- confusionMatrix(data=ada.predictions,reference=traindata$y,positive=NULL)

##  PERFORMANCE DES DIFFERENTS MODELES TESTES PAR VALIDATION CROISEE

perf_ada_fit_cv <- subset(adaboost.fit$results, mfinal == adaboost.fit$bestTune$mfinal & maxdepth == adaboost.fit$bestTune$maxdepth, c("Accuracy", "Kappa"))

##  EVALUATION DE LA QUALITE DU MODELE AVEC LE JEU DE DONNEES TEST
# ada.predictions=predict(adaboost.fit, newdata=testdata)
# save(file="ML/PartieApplications/Ada/Pred_test.Rdata",ada.predictions)
load("ML/PartieApplications/Ada/Pred_test.Rdata")
perf_adaboost_fit_testdata <- confusionMatrix(data=ada.predictions,reference=testdata$y,positive=NULL)

mat_conf_ada <- t(perf_adaboost_fit_testdata$table)
metric_overall_ada <- perf_adaboost_fit_testdata$overall
metric_byClass_ada <- perf_adaboost_fit_testdata$byClass

# ANALYSE DE L'IMPORTANCE DES VARIABLES

ada.varImp <- varImp(adaboost.fit, scale=TRUE)
## Classement par ordre d'importance global
imp_globale <- sort(apply(ada.varImp$importance, 1,function(x){sqrt(sum(x^2))}), decreasing = TRUE)

# GENERER LES RESULTATS

save(mat_conf_ada, file = "ML/PartieApplications/Ada/mat_conf_ada.RData")
save(metric_overall_ada, file = "ML/PartieApplications/Ada/metric_overall_ada.RData")
save(metric_byClass_ada, file = "ML/PartieApplications/Ada/metric_byClass_ada.RData")
write.table(ada.varImp$importance, file = "ML/PartieApplications/Ada/varImp.ada.csv", dec = ".", sep = ";")
```

## eXtreme Gradient Boosting (XGX)

Il s'agit d'un algorithme de machine learning inspiré de la technique de **Gradient Boosting** qui utilise généralement un arbre de décision comme classifieur faible. L'idée du **Gradient Boosting** a été proposée par Leo Breiman en 1997 puis développée par Jérôme H. Friedman en 1999. le principe du gradient boosting est de régresser itérativement un ensemble de classivieur faible (comme des arbres de décisions) sur les érisdus obtenus avec l'arbre précédent. La valeur alors associée à chacune des feuilles est celle qui minimise une fonction de coût spécifique à cet algorithme. Il prend en compte toutes les sorties des classifieurs faibles pour prédire la classe associée à un nouvel échantillon, chacun étant pondéré par un paramètre d'apprentissage.

### Fonctionnement de l'algorithme

On considère un jeu de données à laquelle chacun des échantillons est associée à une variable $y_i$ qui a pour valeur possible 0 et 1 (variable bimodale). Soit $p$ la probabilité que cette variable prenne la valeur 1. On définit alors les odds-ratio, notée odds, de la façon suivante :

```{=tex}
\begin{center}
  $odds=\frac{p}{1-p}$
  
  $p=\frac{e^{log(odds)}}{1+e^{log(odds)}}$
\end{center}
```

On pose alors $F(x_i)=log(odds)$. On peut alors définir la fonction de coût $$L(y_i,F(x_i))$$, définie pour un échantillon $y_i$ de la manière suivante :

```{=tex}
\begin{center}
    $L(y_i,F(x_i))=-y_iF(x_i)+log(1+e^{F(x_i)})$
\end{center}
```

On peut alors démontrer que :

```{=tex}
\begin{center}
    $L(y_i,F(x_i))=-[y_ilog(p)+(1-y_i) \times log(1-p)]$
\end{center}
```

#### Etape 1 : Initialisation

On commence par initialise le modèle avec une valeur constante $F_0(x)$ définie de la manière suivante :

```{=tex}
\begin{center}
  $F_0(x)=argmin_\gamma \sum_{i=1}^nL(y_i,\gamma)$
\end{center}
```

Avec $\gamma=log(odds)$. Cela revient donc à trouver la valeur de $\gamma$ pour laquelle la fonction de coût est minimale, soit la valeur de $\gamma$ pour laquelle la dérivée s'annule. On calcule donc cette dérivée :

```{=tex}
\begin{center}
$\frac{d}{dlog(odds)}(\sum_{i=1}^nL(y_i,\gamma))$

$=\frac{d}{dlog(odds)}(\sum^n_{i=1}[-y_ilog(odds)+log(1+e^{log(odds)})])$

$=\sum^n_{i=1}[-y_i+p]$
\end{center}
```

La première étape de l'algorithme consiste donc à trouver la valeur $\gamma=log(odds)$ pour laquelle $\sum^n_{i=1}[-y_i+p]=0$. On peut donc trouver $p$, puis $\gamma$ par sa relation avec $p$. Pour sa suite, on notera cette valeur $\gamma_0$. Le modèle initialisé est donc la création d'un arbre composé d'une seuile feuille qui prédit que le logarithme du odds ratio associé à l'événement $y_i=1$. On a donc $F_0(x)=\gamma_0$

#### Etape 2 : Coeur de l'algorithme

Soir $m$, le numéro de l'itération.

A) On commence par calculer la $r_{im}$ :

\begin{center} 

  $r_{im}= -[\frac{\delta L(y_i,F(x_i))}{\delta F(x_i)}]_{F(x)=F_{m-1}(x)}$

\end{center}

qui calcule la dérivée de la fonction de coût par rapport à chaque $F(x_i)=log(odds)$ pour chaque échantillon i. $F(x)=F_{m-1}(x)$ indique que le calcul de la dérivée se fait uniquement avec les $F(x_i)$ obtenus à l'étape précédente.

On a donc alors pour tout échantillon i et à l'itération m :


```{=tex}
\begin{center}
  $r_{im}=- \frac{d}{dlog(odds)}(L(y_i,F(x_i)))$
  
  $r_{im}= - [y_i+\frac{e^{log(odds)}}{1+e^{log(odds)}}]$
  
  $r_{im}= - [-y_i + p]$
  
  $r_{im} = [y_i -p]$
\end{center}
```

$r_{im}$ représente les pseudo résidus. On peut ici faire une analogie avec les moindres carrés en régression linéaire où le résidu est la différence entre la valeur observée et la valeur prédite.  Calculer $r_{im}$ revient donc à calculer les pseudos résidus de chaque échantillon i pour l'itération m.

B) On ajuste alors un arbre de régression aux pseudos-résidus $r_{im}$ et crée des feuilles terminales $R_{jm}$ pour chaque feuille j $\in [1,J_m]$. 

C) Pour chaque valeur de $j$ (i.e. chaque feuile $R_{jm}$ de l'arbre créé à l'itération m), on calcule alors $\gamma_{jm}$ :

```{=tex}
\begin{center}
  $\gamma_{jm}=argmin_{\gamma}\sum_{x_j \in R_{ij}}L(y_i,F_{m-1}(x_i)+\gamma)$
\end{center}
```

avec $\gamma_{jm}$ qui correspond à la valeur $\gamma$ qui minimise $\sum_{x_j \in R_{ij}}L(y_i,F_{m-1}(x_i)+\gamma)$. On cherche donc pour chacune des feuilles de l'arbre créé précédemment la valeur $\gamma$ qui minimise $\sum_{x_j \in R_{ij}}L(y_i,F_{m-1}(x_i)+\gamma)$. En remplaçant par l'expression de la fonction de coût, on obtient :


```{=tex}
\begin{center}
  $\sum_{x_j \in R_{ij}}L(y_i,F_{m-1}(x_i)+\gamma)$
  
  $=\sum_{x_j \in R_{ij}}[-y_i \times (F_{m-1}(x_i)+ \gamma)+log(1+e^{F_{m-1}(x_i)+\gamma})]$
\end{center}
```


Trouver le minimum de cette expression en  $\gamma$ nécessite d'approximer $L(y_i,F_{m-1}(x_i)+\gamma)$ avec un polynôme de Taylor du second ordre puis de dériver l'expression obtenue. La valeur $\gamma$ recherchée correspond à celle pour laquelle la dérivée s'annule. A l'issue de cette étape, on démontre que :


```{=tex}
\begin{center}
  $\gamma_{jm}=\frac{\sum_{x_j \in R_{ij}}[y_i-\frac{e^{log(odds)}}{1+e^{log(odds)}}]}{\sum_{x_j \in R_{ij}}p_i(1-p_i)}$
  
  $\gamma_{jm}=\frac{\sum_{x_j \in R_{ij}}[y_i-p_i]}{\sum_{x_j \in R_{ij}}p_i(1-p_i)}$
  
  $\gamma_{jm}=\frac{\sum_{x_j \in R_{ij}}r_{im}}{\sum_{x_j \in R_{ij}}p_i(1-p_i)}$
\end{center}
```

avec $p_i=p(x_i)$, la probabilité que $y_i=1$ pour l'échantillon i. Calculer la valeur de $\gamma$ assocée à chacune des feuilles $R_{jm}$ revient donc à calcumer $\gamma_{jm}$ pour chacune d'elle, telle que défini en dernière ligne. 


D) On peut alors mettre à jour $F_m(x_i)$ pour tout échantillon i : 

```{=tex}
\begin{center}
   $F_m(x_i)=F_{m-1}(x_i)+ \nu \sum_{j=1}^{J_m}\gamma_{jm}I(X_i \in R_{jm})$
\end{center}
```


avec :

- $F_m(x_i)$ le log(odds) obtenu à partir de l'arbre construit à l'itération m pour un échantillon i associé aux variablex $x_i$

- $F_{m-1}(x_i) $le log(odds) obtenu à partir de l'arbre construit à l'itération m-1 pour un échantillon i associé aux variablex $x_i$

-$\nu$ le paramètre d'apprentissage

-$I(X_i \in R_{jm})$ la valeur de la feuille $R_{jm}$. Elle vaut 1 si $x_i \in R_{jm}$, 0 sinon.

Les probabilités associées à $F_m(x_i)$ sont également calculées et mises à jour. 

On répète alors A, B, C et D jusqu'à ce que m=M ou que les résidus obtenus convergent vers 0. 

#### Etape 3 : Obtentiion du classifieur fort en sortie de l'algorithme

A la fin de l'étape 2, on obtient donc le classifieur fort noté $F_M(x)$ :

```{=tex}
\begin{center}
   $F_M(x_i)=F_{M-1}(x_i)+ \nu \sum_{j=1}^{J_M}\gamma_{jM}I(X_i \in R_{jM})$
\end{center}
```



Ce classifieur pourra par la suite être utilisé pour prédite la probabilité qu'un nouvel échantillon i réalise l'évènement $y_i=1$. 

#### Cas particulier de l'eXtreme Gradient Boosting

L'algorithme XGX repose sur l'algorithle de gradient boosting, c'est-à-dire une régression itérative des arbres de décision sur les résidus obtenus avec l'arbre précédent.

Les principales différences reposent sur :


```{=tex}
\begin{itemize}

   \item a construction de l’arbre à chaque étape m. Contrairement au gradient boosting, l’arbre construit à chaque étape est unique : il s’agit de celui qui s’ajuste le mieux aux résidus. Pour trouver cet arbre, plusieurs étapes sont réalisées :
   
   \begin{enumerate}
   
      \item Une seule partie des échantillons et des variables est sélectionnée aléatoirement à chaque étape m. Ce sous-jeu de données sera celui utilisé pour construire l’arbre de régression à l’itération m. Le ratio de variables et le ratio des échantillons sont fixés par l’utilisateur
      
      \item Pour chacun des noeuds de l’arbre de régression potentiel, on calcule le score de similarité de la manière suivante, en utilisant $\lambda geq 0$, un paramètre de régularisation fixé par l'utilisateur. 
      
      \begin{center}
          $score_{similarite}=\frac{\sum_i résidus_i^2}{\sum_i[p_i(1-p_i)]+\lambda}$
      \end{center}
      
      \item A chaque séparation de l’arbre de régression potentiel, on calcule le gain ci-après :
      
      \begin{center}
          $Gain=score_{similarite\_noeud\_gauche}+score_{similarite\_noeud\_droit}-score_{similarite\_noeud\_parent}$
      \end{center}
      
      \item Pour chacune des séparations possibles, on retient celle qui maximise le gain. 
      
      \item Une fois l’arbre de régression créé, celui-ci va être élagué afin d’éviter le sur-ajustement de la façon suivante
      
      \begin{itemize}
        \item Soit $min\_child\_weight$ un paramètre fixé par l’utilisateur. Toutes les feuilles comprenant un nombre de résidus inférieur au paramètre $min\_child\_weight$ seront supprimées. Par défaut, ce paramètre est fixé à 1. 
        
        \item  Soit gamma $\gamma$ un paramètre fixé par l’utilisateur. Pour chacune des feuilles, i.e., pour chacun des noeuds terminaux de l’arbre, on calcule delta=Gain – $\gamma$. Si delta $\geq$ 0 alors on garde la feuille et la séparation dont elle est issue, sinon on la supprime. Le cas échéant, on réitère l’opération pour les nouvelles feuilles obtenues, etc.
      \end{itemize}
    

   \end{enumerate}
   
   \item Le calcul des valeurs de log(odds) associées à chaque feuille. Dans le cas de l’eXtreme Gradient Boosting, on a en effet :
   
   \item Le paramètre d’apprentissage noté $\nu$ en gradient boosting est appelée eta $\eta$ et vaut par défaut 0.3 et peut être optimisé
   
   \item Une parallélisation permet de construire les arbres en même temps ce qui réduit considérablement le temps de calcul

\end{itemize}
```


*Références* :

- Chen, T., He, T., Benesty, M., Khotilovich, V., Tang, Y., Cho, H., Chen, K., Mitchell, R., Cano, I., Zhou, T., Li, M., Xie, J., Lin, M., Geng, Y., Li, Y., 2018. xgboost: Extreme Gradient Boosting.


- Starmer, J., 2020. XGBoost : Part 2: XGBoost Trees For Classification [WWW Document]. URL https://www.youtube.com/watch?v=8b1JEDvenQU

- Starmer, J., 2019a. Gradient Boost Part 3: Classification [WWW Document]. URL https://www.youtube.com/results?search_query=statquest+gradient+boost+part+3

- Starmer, J., 2019b. Gradient Boosting Part 4 : Classification Details [WWW Document]. URL https://www.youtube.com/watch?v=StWY5QWMXCw&t=209s


### Mise en place sous R



```{r}
library(caret)
library(kernlab)

# traindata : jeu de données d'entraînements
# test_select : jeu de données de validation

load(file="ML/PartieApplications/SVM/testdata.Rdata")
load(file="ML/PartieApplications/SVM/traindata.Rdata")


#  RECHERCHE DES PARAMETRES OPTIMAUX

##  CREATION DE LA GRILLE DE PARAMETRISATION ET METHODE POUR TROUVER LES PARAMETRES OPTIMAUX 
set.seed(111) 
metric <- "Accuracy"
control <- trainControl(method="repeatedcv", number=10, repeats=3, search="grid", allowParallel=TRUE)
tunegrid <- expand.grid(mfinal=c(100,150), maxdepth=c(10:30))

##  AJUSTEMENT DU MODELE ADABOOST
# adaboost.fit <- train(y~., data=traindata, method="AdaBag", metric=metric, tuneGrid=tunegrid, trControl=control)

load(file = "ML/PartieApplications/Ada/2019-04-22_model_ADABOOST_TFEN10RECV90NORM.Rdata")

##  PARAMETRES DU MODELE AJUSTE
adaboost.fit$bestTune
plot(adaboost.fit)

# EVALUATION DES PERFORMANCES DE ML 
summary(adaboost.fit)

## PERFORMANCE DU MODELE SUR JEU DE DONNEES D'ENTRAINEMENT
# ada.predictions=predict(adaboost.fit, newdata=traindata)
# save(file="ML/PartieApplications/Ada/Pred_train.Rdata",ada.predictions)
load(file="ML/PartieApplications/Ada/Pred_train.Rdata")
perf_adaboost_fit_traindata <- confusionMatrix(data=ada.predictions,reference=traindata$y,positive=NULL)

##  PERFORMANCE DES DIFFERENTS MODELES TESTES PAR VALIDATION CROISEE
perf_ada_fit_cv <- subset(adaboost.fit$results, mfinal == adaboost.fit$bestTune$mfinal & maxdepth == adaboost.fit$bestTune$maxdepth, c("Accuracy", "Kappa"))

##  EVALUATION DE LA QUALITE DU MODELE AVEC LE JEU DE DONNEES TEST
# ada.predictions=predict(adaboost.fit, newdata=testdata)
# save(file="ML/PartieApplications/Ada/Pred_test.Rdata",ada.predictions)
load(file="ML/PartieApplications/Ada/Pred_test.Rdata")
perf_adaboost_fit_testdata <- confusionMatrix(data=ada.predictions,reference=testdata$y,positive=NULL)

mat_conf_ada <- t(perf_adaboost_fit_testdata$table)
metric_overall_ada <- perf_adaboost_fit_testdata$overall
metric_byClass_ada <- perf_adaboost_fit_testdata$byClass

# ANALYSE DE L'IMPORTANCE DES VARIABLES

ada.varImp <- varImp(adaboost.fit, scale=TRUE)
## Classement par ordre d'importance global
imp_globale <- sort(apply(ada.varImp$importance, 1,function(x){sqrt(sum(x^2))}), decreasing = TRUE)

# GENERER LES RESULTATS
save(mat_conf_ada, file = "ML/PartieApplications/Ada/mat_conf_ada.RData")
save(metric_overall_ada, file = "ML/PartieApplications/Ada/metric_overall_ada.RData")
save(metric_byClass_ada, file = "ML/PartieApplications/Ada/metric_byClass_ada.RData")
write.table(ada.varImp$importance, file = "varImp.ada.csv", dec = ".", sep = ";")
```


## Partial Least-Squares - Discriminant Analysis (PLS-DA)

C'est une méthode de projection multivariée qui modélise la relation entre un ensemble de p variables quantitatives X et une variable qualitative Y à q modalités, variable aussi dite à expliquer. L'objectif de la PLS-DA est de construire T composantes PLS orthogonales entre elles, qui à la fois restituent bien la matrice X et également qui expliquent et prédisent bien le vecteur Y. La question est alors : Comment trouver les composantes T ?

### Exemple à partir de PLS-1 et PLS-2

Dans le cadre de la PLS-1, il y a une variable quantitative à prédire, contre plusieurs dans le cadre de la PLS-2. 

Pour trouver les composantes, on effectue une régression linéaire $y=aX+b$. De façon générale, pour la PLS-1, on définit $y=cT + E$, avec T la matrice des  h composantes. Ces composantes t sont des variables latentes, à savoir des combinaisons linéaires des variables d'origine. Elles sont toutes orthogonales les unes aux autres. Ce modèle ressemble beaucoup au modèle de l'ACP. On peut définir $T=xW$, tel que :


```{=tex}
\begin{center}
  $t_1=w_{11}X_1+w_{12}X_2+...+w_{1m}X_m$
  
  $t_2=w_{21}X_1+w_{22}X_2+...+w_{2m}X_m$
  
  $...$
  
  $t_h=w_{h1}X_1+w_{h2}X_2+...+w_{hm}X_m$
  
\end{center}
```

Trouver la première composante $t_1$ revient à trouver le vecteur propre que l'axe $t_1$ restitue bien la variance de X. Si on étant dans le cas de l'ACP, cela reviendrait à maximiser l'inertie. Si on définit la somme des carrés comme la somme des carrés des distances des points à cet axe, alors la composante $t_1$ est l'axe qui maximise cette somme des carrés. Si l'axe $t_1$ est bien explicatif, la covariance($t_1$,y) est élevée. On cherche donc $t_1=\sum_iw_{1i}X_i=w_1X$ tel que cette covariance soit maximale. On recommence ensuite avec $t_2$, tel que ::

- l'axe restitue bien la variance de la partie de X non expliquée par $t_1$

- l'axe soit bien explicatif, donc que la covariance entre $t_2$ et y soit maximale

- avec la contrainte que $t_2$ et $t_1$ soient orthogonales. 


Dans le cadre de la PLS-2, on passe de $y=cT+E$ à $Y=QT+E$, c'est-à-dire l'expression de $Y$ en fonction de ses composantes latentes, avec T, la matrice de composante latente. On peut alors définit que $Y=UP^T+F$, avec $U=Yc$, tel que :

```{=tex}
\begin{center}
 $u_1=Y_1c_{11}+Y_2c_{12}+...+Y_lc_{1l}$
 
 $u_2=Y_1c_{21}+Y_2c_{22}+...+Y_lc_{2l}$
 
 $...$
 
 $u_h=Y_1c_{h1}+Y_2c_{h2}+...+Y_lc_{hl}$
  
\end{center}
```

La recherche des t composantes en PLS-2 se réalise de la même manière que pour la PLS-1 mais avec une recherche conjointe des composantes t et u tel que la matrice U restitue bien Y et la matrice T restitue bien C, et que la covariance entre U et T soit maximale, sous la contrainte que les composantes t soient orthogonales entre elles, et de même entre les composantes u. 


### Cas particulier de la PLS-DA

Dans le cas de la PLS-DA, on dichotomise une variable multimodale en variable bimodale ayant pour sortie 0 ou 1. La PLS-DA est du coup l'application d'une PLS-2 sur la matrice Y dichotomisée. 

Le nombre optimal de composantes PLS à retenir est obtenu grâce à l'évolution de l'erreur en fonction du nombre de composantes, calculé par cross-validation. De plus, la PLS s'applique toujours sur un jeu de données centré. 

Exemples d'application pertinente de la PLS-DA :

- Lorsqu’on cherche à expliquer ou à prédire des groupes/classes d’individus en fonction de variables quantitatives

- Lorsque les variables quantitatives sont corrélées entre elles

- Lorsqu’il y a plus de prédicteurs que d’observations dans X

- Pour confirmer des tendances remarquées en analyse univariée

- Lorsqu’on cherche à identifier les variables de X les plus discriminantes, soit dans un but explicatif, soit pour sélectionner les variables les plus discriminantes en vue de les intégrer dans un autre modèle de classification. 



L'identification des variables discriminantes se font grâce aux VUP (Variable Importance in Projection). Pour une variable j avec h composantes retenues, elle est définie par :

```{=tex}
\begin{center}
 $VIP_{hj}=\sqrt{\frac{P\sum^h_iw^2_{ik}R^2_i}{R^2_T}}$
\end{center}
```

avec :

- $P$ le nombre de variable dans X

- $w_{ij}$ le coefficient de la variable j dans la composante $t_i$

- $R_i^2$ le pourcentage de variance de Y expliquée par la composante $t_i$

- $R^2_T$ le pourcentage total de variance de Y expliquée


Plus le coefficient $w_{ij}$ associé à la variable j sera fort et associé à une composante très explicative, plus le VIP sera élevé. Un VIP élevé signifie donc que la variable est importante. En pratique, on considère comme importantes les variables pour lesquelles les VIP sur les h composantes retenues sont supérieurs à 0.8. 

*Références* :

- Barker, Matthew, et William Rayens. «Partial Least Squares for Discrimination». Journal of Chemometrics 17, no 3 (24 mars 2003): 166‑73. https://doi.org/10.1002/cem.785.


- Cariou V., 2015. Méthodes inférentielles : MLR, PCR, PLS. Nantes : Oniris, 27p. (Oniris 3ème année orientation statistiques appliquées, Cours)


## HMM - Lissage par Vitervi
